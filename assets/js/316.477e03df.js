(window.webpackJsonp=window.webpackJsonp||[]).push([[316],{591:function(s,t,a){"use strict";a.r(t);var n=a(14),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h4",{attrs:{id:"双写一致"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#双写一致"}},[s._v("#")]),s._v(" "),t("strong",[s._v("双写一致")])]),s._v(" "),t("p",[s._v("1、Cache-aside pattern")]),s._v(" "),t("p",[s._v("读： 先读缓存，没有，读数据库再写缓存")]),s._v(" "),t("p",[s._v("写：写数据库，删缓存 （+ 延时删除）")]),s._v(" "),t("p",[s._v("2、延时双删")]),s._v(" "),t("p",[s._v("为什么需要延时双删，多线程并发请求的情况，存在 t1 从库中读了老数据，t2 去写新数据并且删了缓存，t1 把老数据又写到了缓存里，发生数据不一致")]),s._v(" "),t("p",[s._v("解决方案：")]),s._v(" "),t("p",[s._v("1、Canel 订阅 binlog 去异步删缓存")]),s._v(" "),t("h4",{attrs:{id:"持久化机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#持久化机制"}},[s._v("#")]),s._v(" 持久化机制")]),s._v(" "),t("p",[s._v("rdb+aof")]),s._v(" "),t("p",[s._v("Rdb：全量备份，快照，")]),s._v(" "),t("p",[s._v("aof：增量日志追加备份")]),s._v(" "),t("h4",{attrs:{id:"redis-缓存系统是如何部署的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis-缓存系统是如何部署的"}},[s._v("#")]),s._v(" Redis 缓存系统是如何部署的")]),s._v(" "),t("p",[s._v("两种方式")]),s._v(" "),t("p",[s._v("主从+sentinel")]),s._v(" "),t("p",[s._v("cluster 模式")]),s._v(" "),t("h2",{attrs:{id:"_1-在你的项目中-哪些数据是数据库和-redis-缓存双写的-如何保证双写一致性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-在你的项目中-哪些数据是数据库和-redis-缓存双写的-如何保证双写一致性"}},[s._v("#")]),s._v(" 1.在你的项目中，哪些数据是数据库和 redis 缓存双写的？如何保证双写一致性？")]),s._v(" "),t("h2",{attrs:{id:"_2-系统上线-redis-缓存系统是如何部署的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-系统上线-redis-缓存系统是如何部署的"}},[s._v("#")]),s._v(" 2.系统上线，redis 缓存系统是如何部署的")]),s._v(" "),t("h2",{attrs:{id:"_3-系统上线-redis-缓存给了多大的总内存-命中率多高-抗住了多少-qps-数据流回源会有多少-qps"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-系统上线-redis-缓存给了多大的总内存-命中率多高-抗住了多少-qps-数据流回源会有多少-qps"}},[s._v("#")]),s._v(" 3.系统上线，redis 缓存给了多大的总内存？命中率多高？抗住了多少 QPS？数据流回源会有多少 QPS?")]),s._v(" "),t("h2",{attrs:{id:"_4-热-key-大-value-问题-某个-key-出现了热点缓存导致缓存集群中的某个机器负载过高-如何发现并解决"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-热-key-大-value-问题-某个-key-出现了热点缓存导致缓存集群中的某个机器负载过高-如何发现并解决"}},[s._v("#")]),s._v(" 4.热 key 大 Value 问题，某个 key 出现了热点缓存导致缓存集群中的某个机器负载过高？如何发现并解决？")]),s._v(" "),t("h2",{attrs:{id:"_5-超大-value-打满网卡的问题如何避免这样的问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-超大-value-打满网卡的问题如何避免这样的问题"}},[s._v("#")]),s._v(" 5.超大 value 打满网卡的问题如何避免这样的问题")]),s._v(" "),t("ul",[t("li",[s._v("获取用户 Post 过来的数据，对 Key，Value 长度进行限制，避免产生超大的 Key,Value，打满网卡")]),s._v(" "),t("li",[s._v("可以将超大 value 的数据拆分成几个 Key-value,用 MGET（同时获取多个 key 的值）取值,降低 IO 消耗.")])]),s._v(" "),t("h2",{attrs:{id:"_6-以往的工作经历中-是否出现过缓存集群事故-说说细节并说说高可用保障的方案"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6-以往的工作经历中-是否出现过缓存集群事故-说说细节并说说高可用保障的方案"}},[s._v("#")]),s._v(" 6.以往的工作经历中，是否出现过缓存集群事故？说说细节并说说高可用保障的方案？")]),s._v(" "),t("h2",{attrs:{id:"_7-平时如何监控缓存集群的-qps-和容量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7-平时如何监控缓存集群的-qps-和容量"}},[s._v("#")]),s._v(" 7.平时如何监控缓存集群的 QPS 和容量")]),s._v(" "),t("h2",{attrs:{id:"_8-缓存集群如何扩容"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_8-缓存集群如何扩容"}},[s._v("#")]),s._v(" 8.缓存集群如何扩容？")]),s._v(" "),t("h2",{attrs:{id:"_9-说一下-redis-的集群原理和选举机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_9-说一下-redis-的集群原理和选举机制"}},[s._v("#")]),s._v(" 9.说一下 redis 的集群原理和选举机制")]),s._v(" "),t("h2",{attrs:{id:"_10-key-寻址算法都有哪些"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_10-key-寻址算法都有哪些"}},[s._v("#")]),s._v(" 10.Key 寻址算法都有哪些？")]),s._v(" "),t("h2",{attrs:{id:"_11-redis-线程模型现场画个图说说"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_11-redis-线程模型现场画个图说说"}},[s._v("#")]),s._v(" 11.Redis 线程模型现场画个图说说")]),s._v(" "),t("h2",{attrs:{id:"_12-redis-内存模型现场画个图说说"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_12-redis-内存模型现场画个图说说"}},[s._v("#")]),s._v(" 12.Redis 内存模型现场画个图说说")]),s._v(" "),t("h2",{attrs:{id:"_13-redis-的底层数据结构了解多少"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_13-redis-的底层数据结构了解多少"}},[s._v("#")]),s._v(" 13.redis 的底层数据结构了解多少")]),s._v(" "),t("h2",{attrs:{id:"_14-redis-的单线程特性有什么优缺点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_14-redis-的单线程特性有什么优缺点"}},[s._v("#")]),s._v(" 14.redis 的单线程特性有什么优缺点")]),s._v(" "),t("h2",{attrs:{id:"_15-如何解决缓存击穿的问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_15-如何解决缓存击穿的问题"}},[s._v("#")]),s._v(" 15.如何解决缓存击穿的问题")]),s._v(" "),t("hr"),s._v(" "),t("h2",{attrs:{id:"_1、在项目中缓存是如何使用的-为什么要用缓存-缓存使用不当会造成什么后果"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、在项目中缓存是如何使用的-为什么要用缓存-缓存使用不当会造成什么后果"}},[s._v("#")]),s._v(" 1、在项目中缓存是如何使用的？为什么要用缓存？缓存使用不当会造成什么后果？")]),s._v(" "),t("p",[s._v("为什么要用缓存？")]),s._v(" "),t("p",[s._v("用缓存，主要有两个用途：高性能、高并发。")]),s._v(" "),t("p",[s._v("高性能：")]),s._v(" "),t("p",[s._v("比如 外研社这边 K12 优学 业务中有一个地区树查询接口，要拉取全国省-市-地区三级地区树的结构，从数据库中查询三级结构，至少要有三个 in 查询，查询后的结构后面也基本不怎么变了，这种查询结果 我们就把他扔到缓存里，一次查询走 db，后面的查询直接命中缓存返回")]),s._v(" "),t("p",[s._v("高并发：")]),s._v(" "),t("p",[s._v("我在天脉的时候，做的一些秒杀类似的业务（比如游戏抽奖，每天签到奖励这类的业务），先参与的人往往会获得更高的奖励，在某一时间点会产生大量的流量，如果这些大流量 的操作直接到了数据库，数据库肯定扛不住；\n一方面，我们会把高并发会涉及到的业务数据写入缓存，比如用户签到，我们会在 redis 中用 hashTable 保存用户的连签信息，bonus 信息（比如生日）等\n另一方面，还有会用 redis 实现分布式锁，起到限流的效果，限制用户在 10s 内只能触发一次签到操作")]),s._v(" "),t("p",[s._v("id-only 服务：")]),s._v(" "),t("p",[s._v("用 list 做 id 池，用 hash 保存 application 的信息（currentOffset 等属性）")]),s._v(" "),t("h2",{attrs:{id:"_2、redis-和-memcached-有什么区别-redis-的线程模型是什么-为什么-redis-单线程却能支撑高并发"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、redis-和-memcached-有什么区别-redis-的线程模型是什么-为什么-redis-单线程却能支撑高并发"}},[s._v("#")]),s._v(" 2、redis 和 memcached 有什么区别？redis 的线程模型是什么？为什么 redis 单线程却能支撑高并发")]),s._v(" "),t("ul",[t("li",[s._v("redis 支持复杂的数据结构")]),s._v(" "),t("li",[s._v("redis 原生支持集群模式")]),s._v(" "),t("li",[s._v("redis 大 key 没有 memcache 快")])]),s._v(" "),t("p",[s._v("线程模型：")]),s._v(" "),t("p",[s._v("单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。")]),s._v(" "),t("p",[s._v("为什么 redis 单线程却能支撑高并发：")]),s._v(" "),t("ul",[t("li",[s._v("纯内存操作")]),s._v(" "),t("li",[s._v("非阻塞的 IO 多路复用机制")]),s._v(" "),t("li",[s._v("避免了多线程的频繁上下文切换问题")])]),s._v(" "),t("h2",{attrs:{id:"_3、redis-都有哪些数据类型-分别在哪些场景下使用比较合适-redis-的底层数据结构了解多少"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、redis-都有哪些数据类型-分别在哪些场景下使用比较合适-redis-的底层数据结构了解多少"}},[s._v("#")]),s._v(" 3、redis 都有哪些数据类型？分别在哪些场景下使用比较合适？redis 的底层数据结构了解多少")]),s._v(" "),t("p",[s._v("字符串 String、列表 List、字典 Hash、集合 Set、有序集合 SortedSet")]),s._v(" "),t("p",[s._v("string：简单动态字符串 SDS")]),s._v(" "),t("p",[s._v("hash ：底层实现：压缩列表，哈希表")]),s._v(" "),t("p",[s._v("存放的是结构化的对象")]),s._v(" "),t("p",[s._v("场景：我在做单点登录的时候，就是用这种数据结构存储单条用户信息，以 "),t("code",[s._v("CookieId")]),s._v(" 作为 Key，设置 30 分钟为缓存过期时间，能很好的模拟出类似 "),t("code",[s._v("Session")]),s._v(" 的效果。")]),s._v(" "),t("p",[s._v("List：底层实现：压缩列表，链表")]),s._v(" "),t("p",[s._v("使用 List 的数据结构，可以做简单的消息队列的功能。"),t("code",[s._v("rpush+blpop")]),s._v("实现先进先出；\n另外还有一个就是，可以利用 "),t("code",[s._v("lrange")]),s._v(" 命令，做基于 Redis 的分页功能，性能极佳，用户体验好，类似粉丝列表、文章的评论列表之类，微博那种下拉不断分页的东西。\nset ： 底层实现：hash 表(不带 value)")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("全局去重的功能;因为 Set 堆放的是一堆不重复值的集合。所以可以做全局去重的功能")])]),s._v(" "),t("li",[t("p",[s._v("利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。\nZSet ：底层实现：跳表")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("Sorted Set")]),s._v("多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。")])]),s._v(" "),t("li",[t("p",[s._v("可以做排行榜应用，取 "),t("code",[s._v("TOP N")]),s._v(" 操作。")])]),s._v(" "),t("li",[t("p",[t("code",[s._v("Sorted Set")]),s._v(" 可以用来做延时任务。最后一个应用就是可以做范围查找。")])])]),s._v(" "),t("p",[s._v("其他一些数据结构")]),s._v(" "),t("p",[s._v("HyperLogLog、Geo、Pub/Sub")]),s._v(" "),t("p",[s._v("Redis Module")]),s._v(" "),t("p",[s._v("BloomFilter，RedisSearch，Redis-ML")]),s._v(" "),t("h2",{attrs:{id:"_4、redis-的过期策略都有哪些-内存淘汰机制都有哪些-手写一下-lru-代码实现"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4、redis-的过期策略都有哪些-内存淘汰机制都有哪些-手写一下-lru-代码实现"}},[s._v("#")]),s._v(" 4、redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？")]),s._v(" "),t("p",[s._v("过期策略")]),s._v(" "),t("p",[t("strong",[s._v("定期删除+惰性删除")])]),s._v(" "),t("p",[s._v("定期删除，redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。")]),s._v(" "),t("p",[s._v("惰性删除，获取某个 Key 的时候，Redis 会检查一下，这个 Key 如果设置了过期时间，如果过期了此时就会删除。")]),s._v(" "),t("p",[s._v("内存淘汰机制：")]),s._v(" "),t("p",[s._v("如果没有过期的 Key 被"),t("strong",[s._v("定期删除 或 惰性删除")]),s._v("，内存不断增长，怎么办？内存不够用了怎么办？")]),s._v(" "),t("p",[s._v("在 redis.conf 中有一行配置：")]),s._v(" "),t("div",{staticClass:"language-shell line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# maxmemory-policy volatile-lru")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("六种内存淘汰策略：")]),s._v(" "),t("ul",[t("li",[s._v("noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。")]),s._v(" "),t("li",[t("strong",[s._v("allkeys-lru")]),s._v("：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。推荐使用，目前项目在用这种。")]),s._v(" "),t("li",[s._v("allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。应该也没人用吧，你不删最少使用 Key，去随机删。")]),s._v(" "),t("li",[s._v("volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。不推荐。")]),s._v(" "),t("li",[s._v("volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。依然不推荐。")]),s._v(" "),t("li",[s._v("volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。不推荐。\n推荐使用：allkeys-lru")])]),s._v(" "),t("p",[s._v("手写下 LRU 代码实现：")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("LRUCache")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" val"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),s._v(" pre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),s._v(" next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" val"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("key "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("val "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" val"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pre "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("removeNode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),s._v(" node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pre "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("addNodeToTail")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),s._v(" node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pre "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tail"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tail"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pre"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        tail"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pre "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" capacity"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Map")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" hash "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("HashMap")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),s._v(" head "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),s._v(" tail "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("LRUCache")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" capacity"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("capacity "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" capacity"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        head"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tail"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        tail"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pre "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" head"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),s._v("hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("containsKey")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("removeNode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("addNodeToTail")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("val"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("public")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!")]),s._v("hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("containsKey")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("size")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" capacity"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("remove")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("head"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("removeNode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("head"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("containsKey")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("removeNode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),s._v(" node "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("addNodeToTail")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("node"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br")])]),t("h2",{attrs:{id:"_5-如何保证-redis-的高并发和高可用-redis-的主从复制原理能介绍一下么-redis-的哨兵原理能介绍一下么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-如何保证-redis-的高并发和高可用-redis-的主从复制原理能介绍一下么-redis-的哨兵原理能介绍一下么"}},[s._v("#")]),s._v(" 5.如何保证 redis 的高并发和高可用？redis 的主从复制原理能介绍一下么？redis 的哨兵原理能介绍一下么？")]),s._v(" "),t("p",[s._v("redis 主从架构")]),s._v(" "),t("p",[s._v("redis 基于哨兵实现高可用 redis 实现高并发主要依靠主从架构，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万 QPS，多从用来查询数据，多个从实例可以提供每秒 10w 的 QPS。")]),s._v(" "),t("p",[s._v("如果想要在实现高并发的同时，容纳大量的数据，那么就需要 redis 集群，使用 redis 集群之后，可以提供每秒几十万的读写并发。")]),s._v(" "),t("p",[s._v("redis 高可用，如果是做主从架构部署，那么加上哨兵就可以了，就可以实现，任何一个实例宕机，可以进行主备切换。")]),s._v(" "),t("h2",{attrs:{id:"_6、redis-的持久化有哪几种方式-不同的持久化机制都有什么-优缺点-持久化机制具体底层是如何实现的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6、redis-的持久化有哪几种方式-不同的持久化机制都有什么-优缺点-持久化机制具体底层是如何实现的"}},[s._v("#")]),s._v(" 6、redis 的持久化有哪几种方式？不同的持久化机制都有什么 优缺点？持久化机制具体底层是如何实现的？")]),s._v(" "),t("p",[s._v("问题背景：")]),s._v(" "),t("p",[s._v("如果 redis 的数据都在内存里，一旦宕机重启，内存数据丢失。造成缓存雪崩，数据库挂掉")]),s._v(" "),t("p",[s._v("所以，我们必须使用 redis 的持久化机制，将数据写入内存，在重启的时候尽量少丢数据")]),s._v(" "),t("p",[s._v("A:")]),s._v(" "),t("p",[s._v("redis 持久化的两种方式")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("RDB：RDB 持久化机制，是对 redis 中的数据执行周期性的持久化。")])]),s._v(" "),t("li",[t("p",[s._v("AOF：AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在 redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集。\n两种方式结合使用：")])]),s._v(" "),t("li",[t("p",[s._v("RDB：备份周期长，会丢失更多数据；但恢复快")])]),s._v(" "),t("li",[t("p",[s._v("AOF：恢复时间长，时间间隔一秒，丢失数据少")])])])])}),[],!1,null,null,null);t.default=e.exports}}]);