(window.webpackJsonp=window.webpackJsonp||[]).push([[202],{476:function(_,v,a){"use strict";a.r(v);var r=a(14),e=Object(r.a)({},(function(){var _=this,v=_._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[v("ul",[v("li",[_._v("kafka 的哪些设计让它有如此高的性能")]),_._v(" "),v("li",[_._v("当你使用 kafka-topics.sh 创建一个 topic 之后，Kafka 背后会执行什么逻辑？")]),_._v(" "),v("li",[_._v("Kafka Controller 的职责有哪些？")]),_._v(" "),v("li",[_._v("如果指定一个 offset，Kafka Controller 怎么查找对应的消息？")]),_._v(" "),v("li",[_._v("kafka 中哪些地方需要选举？这些地方的选举策略又是哪些？")]),_._v(" "),v("li",[_._v("有哪些情景会造成消息漏消费？")]),_._v(" "),v("li",[_._v("有哪些情形会造成重复消费？")]),_._v(" "),v("li",[_._v("如何选择 Partiton 的数量")]),_._v(" "),v("li",[_._v("leader、broker、controller 宕机会如何处理")]),_._v(" "),v("li",[_._v("Connector 和 Stream 的使用场景")])]),_._v(" "),v("hr"),_._v(" "),v("h2",{attrs:{id:"_1、消息队列的主要作用是什么"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1、消息队列的主要作用是什么"}},[_._v("#")]),_._v(" 1、消息队列的主要作用是什么？")]),_._v(" "),v("p",[_._v("项目好好的情况下，为什么要引入消息队列？引入的理由是什么？")]),_._v(" "),v("p",[_._v("主要功能：异步，削峰，解耦")]),_._v(" "),v("p",[_._v("其他功能：数据同步，数据冗余，业务日志记录")]),_._v(" "),v("h2",{attrs:{id:"_2、你们的项目里是怎么用消息队列的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2、你们的项目里是怎么用消息队列的"}},[_._v("#")]),_._v(" 2、你们的项目里是怎么用消息队列的？")]),_._v(" "),v("ul",[v("li",[v("p",[_._v("我们使用 kafka 集群作为消息队列，一般为奇数台（3 台）")])]),_._v(" "),v("li",[v("p",[_._v("副本集设置为 2，需要保证顺序的消息 partition 设置为 1")])]),_._v(" "),v("li",[v("p",[_._v("生产者：ack 设置为 1（0：至多一次；1：至少一次；-1：精准一次），消费者做幂等性")])]),_._v(" "),v("li",[v("p",[_._v("消费者：")]),_._v(" "),v("p",[_._v("1、消费者客户端根据业务通过 groupId 分组；手动提交 offset；")]),_._v(" "),v("p",[_._v("2、分区数一般设置为 2 的次方个，通常为 16，因为项目主机数目一般也是 2 的次方，防止 offset 偏移过大；")])])]),_._v(" "),v("h3",{attrs:{id:"_3、推和拉的消费方式对比-kafka-用的哪种方式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3、推和拉的消费方式对比-kafka-用的哪种方式"}},[_._v("#")]),_._v(" 3、推和拉的消费方式对比？kafka 用的哪种方式？")]),_._v(" "),v("p",[_._v("生产者使用推的方式，消费者使用拉的方式")]),_._v(" "),v("p",[_._v("一般指消费者，拉的方式的好处，可以根据自己的处理能力决定拉取速度；")]),_._v(" "),v("h2",{attrs:{id:"_3、在项目中如何保证消息队列的高可用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3、在项目中如何保证消息队列的高可用"}},[_._v("#")]),_._v(" 3、在项目中如何保证消息队列的高可用")]),_._v(" "),v("ul",[v("li",[v("p",[_._v("N 台集群（奇数台）")])]),_._v(" "),v("li",[v("p",[_._v("replica 副本机制 配置过半数个副本")])]),_._v(" "),v("li",[v("p",[_._v("监控")])])]),_._v(" "),v("h3",{attrs:{id:"_5、如何保证-kafka-消息不丢-会不会丢消息-怎么处理的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5、如何保证-kafka-消息不丢-会不会丢消息-怎么处理的"}},[_._v("#")]),_._v(" 5、如何保证 Kafka 消息不丢？会不会丢消息？怎么处理的?")]),_._v(" "),v("p",[v("strong",[_._v("消息丢失")])]),_._v(" "),v("p",[_._v("会发生在 Broker、Producer 和 Consumer")]),_._v(" "),v("p",[_._v("Producer 丢失消息：发生在生产者客户端，异步批量发送，buffer 会丢；Ack 设置为 0，all, 1 都可能发生消息丢失；")]),_._v(" "),v("p",[_._v("Broker 丢消息场景：异步批量刷盘机制 + ack 确认 -> 改为同步刷盘")]),_._v(" "),v("p",[_._v("consumer 丢数据场景：发生在客户端，自动提交 offset，间隔一段时间（默认 1s）异步的提交，如果这时消息没有处理完，会存在丢失；如果是手动提交，则不存在消息丢失问题，但是会重复消费")]),_._v(" "),v("h3",{attrs:{id:"_6、如何保证消息不重复-exactly-once-语义"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6、如何保证消息不重复-exactly-once-语义"}},[_._v("#")]),_._v(" "),v("strong",[_._v("6、如何保证消息不重复？Exactly-Once 语义")])]),_._v(" "),v("p",[_._v("Exactly-Once 即精准一次性，核心思想是做到两个方面：")]),_._v(" "),v("ul",[v("li",[_._v("消息不丢")]),_._v(" "),v("li",[_._v("消息处理实现幂等性\n消息不丢可以参考上面第 5 个问题")])]),_._v(" "),v("p",[_._v("我们在日常开发中，需要思考 消息丢失、消息重复 等场景，我们应如何进行处理")]),_._v(" "),v("p",[_._v("Kafka 中的消息会不会丢失或重复消费?")]),_._v(" "),v("p",[_._v("从两个方面分析入手："),v("strong",[_._v("生产者发送消息")]),_._v("和"),v("strong",[_._v("消息者消费消息")])]),_._v(" "),v("p",[v("strong",[_._v("消息发送")])]),_._v(" "),v("p",[_._v("Kafka 消息发送有两种方式：同步（sync）和异步（async），默认是同步方式，可通过 producer.type 属性进行配置。")]),_._v(" "),v("p",[v("strong",[_._v("ACK 机制")])]),_._v(" "),v("p",[_._v("Kafka 通过配置 request.required.acks 属性来确认消息的生产：")]),_._v(" "),v("ul",[v("li",[_._v("0: 表示不进行消息接收是否成功的确认；")]),_._v(" "),v("li",[_._v("1: 表示当 Leader 接收成功时确认；")]),_._v(" "),v("li",[_._v("-1: 表示 Leader 和 Follower 都接收成功时确认；")])]),_._v(" "),v("p",[_._v("综上所述，有 6 种消息生产的情况，下面分情况来分析消息丢失的场景：")]),_._v(" "),v("ol",[v("li",[_._v("acks=0，不和 Kafka 集群进行消息接收确认，则当网络异常、缓冲区满了等情况时，消息可能丢失；")]),_._v(" "),v("li",[_._v("acks=1，同步模式下，只有 Leader 确认接收成功后但挂掉了，副本没有同步，数据可能丢失；\n"),v("strong",[_._v("消息消费")])])]),_._v(" "),v("p",[_._v("Kafka 消息消费有两个 consumer 接口，Low-level API 和 High-level API：")]),_._v(" "),v("ul",[v("li",[_._v("Low-level API：消费者自己维护 offset 等值，可以实现对 Kafka 的完全控制；")]),_._v(" "),v("li",[_._v("High-level API：封装了对 parition 和 offset 的管理，使用简单；\n如果使用高级接口 High-level API，可能存在一个问题就是当消息消费者从集群中把消息取出来、并提交了新的消息 offset 值后，还没来得及消费就挂掉了，那么下次再消费时之前没消费成功的消息就“诡异”的消失了；")])]),_._v(" "),v("p",[_._v("解决办法：")]),_._v(" "),v("ul",[v("li",[_._v("针对消息丢失：同步模式下，确认机制设置为-1，即让消息写入 Leader 和 Follower 之后再确认消息发送成功；异步模式下，为防止缓冲区满，可以在配置文件设置不限制阻塞超时时间，当缓冲区满时让生产者一直处于阻塞状态；")]),_._v(" "),v("li",[_._v("针对消息重复：将消息的唯一标识保存到外部介质中，每次消费时判断是否处理过即可。\n"),v("strong",[_._v("如何保证精准一次性")])])]),_._v(" "),v("p",[_._v("精准一次性 = 至少一次性 + 幂等性")]),_._v(" "),v("p",[v("strong",[_._v("至少一次性")])]),_._v(" "),v("p",[v("strong",[_._v("幂等性")])]),_._v(" "),v("p",[_._v("另一种说法是：如何保证消息不被重复消费？")]),_._v(" "),v("p",[_._v("通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据处理结果是一致的")]),_._v(" "),v("p",[_._v("幂等性 通常是通过业务来保证的")]),_._v(" "),v("p",[_._v("列举几个业务场景：")]),_._v(" "),v("ul",[v("li",[v("p",[_._v("比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。")])]),_._v(" "),v("li",[v("p",[_._v("比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。")])]),_._v(" "),v("li",[v("p",[_._v("比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。")])]),_._v(" "),v("li",[v("p",[_._v("比如更新数据库操作时，使用乐观锁机制，类似 update x set xx where version <=")])]),_._v(" "),v("li",[v("p",[_._v("如果你所面临的场景更为复杂，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。")])])]),_._v(" "),v("p",[_._v("当然，如何"),v("strong",[_._v("保证 MQ 的消费是幂等性的，需要结合具体的业务来看")])]),_._v(" "),v("h2",{attrs:{id:"_5-kafka、activemq、rabbitmq、rocketmq-都有什么区别"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5-kafka、activemq、rabbitmq、rocketmq-都有什么区别"}},[_._v("#")]),_._v(" 5.kafka、activemq、rabbitmq、rocketmq 都有什么区别")]),_._v(" "),v("p",[_._v("目前只接触过 kafka，此问题 TODO")]),_._v(" "),v("h2",{attrs:{id:"_6-假设队列满了如何防止消息丢失"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6-假设队列满了如何防止消息丢失"}},[_._v("#")]),_._v(" 6.假设队列满了如何防止消息丢失")]),_._v(" "),v("p",[_._v("（1）生产者可以采用重试机制。因为消费者会不停的消费消息，可以重试将消息放入队列。")]),_._v(" "),v("p",[_._v("如果还是不行，可以将消息记录到数据库，后期做补偿。（不太推荐，不方便）")]),_._v(" "),v("p",[_._v("（2）死信队列，可以理解为备胎。（推荐使用）")]),_._v(" "),v("p",[_._v("即在消息过期，队列满了，消息被拒绝的时候，都可以扔给死信队列。")]),_._v(" "),v("p",[_._v("如果出现死信队列和普通队列都满的情况，此时考虑消费者消费能力不足，可以对消费者开多线程进行处理。")]),_._v(" "),v("h2",{attrs:{id:"_7-消费者消费信息-如何保证-mq-幂等性"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_7-消费者消费信息-如何保证-mq-幂等性"}},[_._v("#")]),_._v(" 7.消费者消费信息，如何保证 MQ 幂等性")]),_._v(" "),v("p",[_._v("ack = 1, 消费者做幂等性；消费者幂等性方案：乐观锁判断、")]),_._v(" "),v("p",[_._v("如果 ack=-1，实现方案复杂，且分布式一致性的实现会导致消息处理延时较高，不能满足消息队列高吞吐、低时延的要求，故不可取")]),_._v(" "),v("h2",{attrs:{id:"_8-谈谈你对死信队列的理解"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_8-谈谈你对死信队列的理解"}},[_._v("#")]),_._v(" 8.谈谈你对死信队列的理解")]),_._v(" "),v("p",[v("strong",[_._v("死信队列")]),_._v("：由于某些原因消息无法被正确的投递，为了确保消息不会被无故的丢弃，一般将其置于一个特殊角色的队列，这个队列一般称之为死信队列")]),_._v(" "),v("h5",{attrs:{id:"消息变成死信有以下几种情况"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#消息变成死信有以下几种情况"}},[_._v("#")]),_._v(" 消息变成死信有以下几种情况")]),_._v(" "),v("ul",[v("li",[_._v("消息被拒绝，无法消费")]),_._v(" "),v("li",[_._v("消息 TTL 过期")]),_._v(" "),v("li",[_._v("队列达到最大长度")])]),_._v(" "),v("h2",{attrs:{id:"_9-如果百万级别的消息积压了-你们如何处理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_9-如果百万级别的消息积压了-你们如何处理"}},[_._v("#")]),_._v(" 9.如果百万级别的消息积压了，你们如何处理？")]),_._v(" "),v("p",[_._v("是否是有效消息？如果无效，启动一个消费者，直接扔掉；")]),_._v(" "),v("p",[_._v("如果是有效消息需要处理，增加消费者数量")]),_._v(" "),v("p",[_._v("如果消费者数量达到了 partition 数量，可以考虑下面的几种方案：")]),_._v(" "),v("ol",[v("li",[_._v("partition 扩容")]),_._v(" "),v("li",[_._v("启动 redis 轻量级消息队列暂存消息，多线程处理")]),_._v(" "),v("li",[_._v("使用 java 的线程池进行多线程处理")])]),_._v(" "),v("h3",{attrs:{id:"_10-为什么不用其他-mq-最终选择了-kafka"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_10-为什么不用其他-mq-最终选择了-kafka"}},[_._v("#")]),_._v(" 10.为什么不用其他 MQ，最终选择了 Kafka?")]),_._v(" "),v("p",[_._v("吞吐量大")]),_._v(" "),v("h3",{attrs:{id:"_12、kafka-中都有哪些选举机制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_12、kafka-中都有哪些选举机制"}},[_._v("#")]),_._v(" "),v("strong",[_._v("12、Kafka 中都有哪些选举机制")])]),_._v(" "),v("p",[v("strong",[_._v("1、控制器的选举")])]),_._v(" "),v("p",[_._v("在 Kafka 集群中会有一个或多个 broker，其中有一个 broker 会被选举为控制器（"),v("code",[_._v("Kafka Controller")]),_._v("），它负责管理整个集群中所有分区和副本的状态等工作。比如当某个分区的"),v("code",[_._v("leader")]),_._v("副本出现故障时，由控制器负责为该分区选举新的 leader 副本。再比如当检测到某个分区的"),v("code",[_._v("ISR")]),_._v("集合发生变化时，由控制器负责通知所有"),v("code",[_._v("broker")]),_._v("更新其元数据信息。")]),_._v(" "),v("p",[v("code",[_._v("Kafka Controller")]),_._v("的选举是依赖"),v("code",[_._v("Zookeeper")]),_._v("来实现的，在 Kafka 集群中"),v("strong",[_._v("哪个 broker 能够成功创建/controller 这个临时（EPHEMERAL）节点他就可以成为 Kafka Controller")]),_._v("。")]),_._v(" "),v("p",[v("strong",[_._v("2、分区 leader 的选举")])]),_._v(" "),v("p",[_._v("Kafka 将每个 Topic 进行分区 Patition，以提高消息的并行处理，同时为保证高可用性，每个分区都有一定数量的副本 Replica，这样当部分服务器不可用时副本所在服务器就可以接替上来，保证系统可用性。")]),_._v(" "),v("p",[_._v("在 Leader 上负责读写，Follower 负责数据的同步。"),v("strong",[_._v("当一个 Leader 发生故障如何从 Follower 中选择新 Leader 呢？")])]),_._v(" "),v("p",[_._v("Kafka 在 Zookeeper 上针对每个 Topic 都维护了一个 ISR（"),v("code",[_._v("in-sync replica")]),_._v("--已同步的副本）的集合，集合的增减 Kafka 都会更新该记录。")]),_._v(" "),v("p",[_._v("如果某分区的 Leader 不可用，Kafka 就从"),v("code",[_._v("ISR")]),_._v("集合中选择一个副本作为新的 Leader。这样就可以容忍的失败数比较高，假如某 Topic 有 N+1 个副本，则可以容忍 N 个服务器不可用。")]),_._v(" "),v("p",[_._v("如果 ISR 中副本都不可用，有两种处理方法：")]),_._v(" "),v("ol",[v("li",[_._v("等待 ISR 集合中副本复活后选择一个可用的副本；")]),_._v(" "),v("li",[_._v("选择集群中其他可用副本；")]),_._v(" "),v("li",[_._v("消费者相关的选举")])]),_._v(" "),v("h3",{attrs:{id:"_13、消费者-rebalance-机制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_13、消费者-rebalance-机制"}},[_._v("#")]),_._v(" 13、消费者 rebalance 机制")]),_._v(" "),v("p",[_._v("RoundRobin、Range")]),_._v(" "),v("h3",{attrs:{id:"_14、kafka-的哪些设计让它有如此高的性能"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_14、kafka-的哪些设计让它有如此高的性能"}},[_._v("#")]),_._v(" "),v("strong",[_._v("14、kafka 的哪些设计让它有如此高的性能？")])]),_._v(" "),v("p",[_._v("kafka 如何实现高性能？高效读写机制")]),_._v(" "),v("ul",[v("li",[_._v("分布式部署")]),_._v(" "),v("li",[_._v("顺序写磁盘")]),_._v(" "),v("li",[_._v("零拷贝技术")]),_._v(" "),v("li",[_._v("分区策略(生产者和消费者)")])])])}),[],!1,null,null,null);v.default=e.exports}}]);